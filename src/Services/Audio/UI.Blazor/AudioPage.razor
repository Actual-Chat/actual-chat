@page "/voice"
@inherits ComputedStateComponent<int>
@using Stl.Time
@using System.Threading.Channels
@using ActualChat.Streaming
@implements IAudioRecorderBackend
@inject IJSRuntime _js
@inject JSModule _jsModule;
@inject Session _session
@inject UICommandRunner _cmd
@inject IAudioUploader _audioUploader
@inject IStreamer<BlobPart> _blobStreamer
@inject IStreamer<TranscriptPart> _transcriptStreamer
@inject ILogger<AudioPage> _log

<h1>Voice Transcription</h1>

<AuthorizeView>
    <NotAuthorized>
        <SignInDropdown Why="to use this page"/>
    </NotAuthorized>
    <Authorized>
        <Row>
            <Column ColumnSize="ColumnSize.Is6.OnDesktop.Is12.OnTablet">
                <Paragraph>
                </Paragraph>

                <Form @onsubmit="StartRecording" Margin="Margin.Is3.OnY">
                    <Addons>
                        <Addon AddonType="AddonType.Start">
                            <Button Type="@ButtonType.Button" Clicked="ToggleRecording" Color="@ToggleColor">
                                <Blazorise.Icon Name="@FontAwesomeIcons.Microphone"/>
                                @ToggleText
                            </Button>
                        </Addon>
                    </Addons>
                </Form>
            </Column>
        </Row>
    </Authorized>
</AuthorizeView>

@code {
    private IJSObjectReference? ModuleRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend>? ComponentRef { get; set; }
    private ChannelWriter<BlobPart>? Writer { get; set; }
    private int Index { get; set; }

    private bool IsRecording { get; set; } = false;
    private Color ToggleColor { get; set; } = Color.Secondary;
    private string ToggleText { get; set; } = "Start Recording";

    public override ValueTask DisposeAsync()
    {
        ComponentRef?.Dispose();
        return base.DisposeAsync();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (ModuleRef != null || !firstRender)
            return;
        ModuleRef = await _jsModule.Import(typeof(AudioPage).Assembly, "js/audio-recorder.js");
        ComponentRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
        await ModuleRef.InvokeVoidAsync("initialize", ComponentRef);
    }

    protected override Task<int> ComputeState(CancellationToken cancellationToken)
    {
        return Task.FromResult(1);
    }

    private async Task StartRecording()
    {
        await ModuleRef!.InvokeVoidAsync("startRecording");
    }

    private async Task StopRecording()
    {
        await ModuleRef!.InvokeVoidAsync("stopRecording");
    }

    private async Task ToggleRecording()
    {
        if (IsRecording)
        {
            await StopRecording();
            ToggleColor = Color.Secondary;
            ToggleText = "Start Recording";
        }
        else
        {
            await StartRecording();
            ToggleColor = Color.Primary;
            ToggleText = "Recording...";
        }
        IsRecording = !IsRecording;

        StateHasChanged();
    }

    [JSInvokable]
    public Task RecordingStarted()
    {
        if (Writer == null)
        {
            var channel = Channel.CreateBounded<BlobPart>(
                new BoundedChannelOptions(100) {
                    FullMode = BoundedChannelFullMode.Wait,
                    SingleReader = true,
                    SingleWriter = true,
                    AllowSynchronousContinuations = true
                });
            Writer = channel.Writer;

            var recording = new AudioRecord(
                "1",
                new AudioFormat { Codec = AudioCodec.Opus, ChannelCount = 1, SampleRate = 48_000 },
                "RU-ru",
                CpuClock.Now.EpochOffset.TotalSeconds);
            _ = _audioUploader.Upload(_session, recording, channel.Reader, CancellationToken.None);

            // _ = ReadAudio(recordingId);
            // _ = ReadTranscription(recordingId);
        }

        return Task.CompletedTask;
    }

    private async Task ReadAudio(AudioRecordId audioRecordId)
    {
        var streamId = new StreamId(audioRecordId, 0);
        var reader = await _blobStreamer.GetStream(streamId, CancellationToken.None);
        await foreach (var audioMessage in reader.ReadAllAsync()) {
            Console.WriteLine($"Got from server: {audioMessage.Chunk.Length} bytes");
        }
    }

    private async Task ReadTranscription(AudioRecordId audioRecordId)
    {
        var streamId = new StreamId(audioRecordId, 0);
        var reader = await _transcriptStreamer.GetStream(streamId, CancellationToken.None);
        await foreach (var transcriptMessage in reader.ReadAllAsync()) {
            Console.WriteLine($"Got from server: {transcriptMessage.Text}");
        }
    }

    [JSInvokable]
    public async Task AudioDataAvailable(string dataAsBase64)
    {
        if (Writer != null) {
            var base64 = Base64Encoded.Decode(dataAsBase64);

            await Writer.WriteAsync(new BlobPart(Index++, base64.Data));
        }
    }

    [JSInvokable]
    public Task RecordingStopped()
    {
        // _ = _cmd.Run(new CompleteAudioRecording(RecordingId));

        Writer?.Complete();
        Writer = null;
        return Task.CompletedTask;
    }
}

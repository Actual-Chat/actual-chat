@using System.Threading.Channels
@using ActualChat.Streaming
@namespace ActualChat.Audio.UI.Blazor
@implements IAudioRecorderBackend
@implements IAsyncDisposable
@inject Session _session
@inject IJSRuntime _js
@inject ISourceAudioRecorder _sourceAudioRecorder

<button @onclick ="ToggleRecording" >
    ðŸŽ¤
</button>

@code {
    private IJSObjectReference ModuleRef { get; set; } = null!;
    private IJSObjectReference? JSComponentRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend> ComponentRef { get; set; } = null!;
    private Channel<BlobPart>? AudioChannel { get; set; }
    private int Index { get; set; }

    private bool IsRecording => AudioChannel != null;
    //private Color ToggleColor => IsRecording ? Color.Secondary : Color.Primary;

    [Parameter]
    public string ChatId { get; set; } = "";

    public async ValueTask DisposeAsync()
    {
        await StopRecording();
        ComponentRef?.Dispose();
        if (JSComponentRef != null)
            await JSComponentRef.DisposeAsync();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender) {
            ComponentRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
            JSComponentRef = await _js.InvokeAsync<IJSObjectReference>($"{WebpackBundles.Main}.audio.create", ComponentRef);
        }
    }

    private Task ToggleRecording()
        => IsRecording ? StopRecording() : StartRecording();

    private async Task StartRecording()
    {
        if (AudioChannel != null)
            return;

        AudioChannel = Channel.CreateBounded<BlobPart>(
            new BoundedChannelOptions(100) {
                FullMode = BoundedChannelFullMode.Wait,
                SingleWriter = true,
                AllowSynchronousContinuations = true,
            });
        StateHasChanged();
        if (JSComponentRef != null)
            await JSComponentRef.InvokeVoidAsync("startRecording");
    }

    private async Task StopRecording()
    {
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
        if (JSComponentRef != null)
          await JSComponentRef.InvokeVoidAsync("stopRecording");
    }

    // JS backend callback handlers

    [JSInvokable]
    public void OnStartRecording()
    {
        if (AudioChannel == null)
            return;

        var audioFormat = new AudioFormat {
            Codec = AudioCodec.Opus,
            ChannelCount = 1,
            SampleRate = 48_000
        };
        var clientStartOffset = CpuClock.Now.EpochOffset.TotalSeconds;
        var audioRecord = new AudioRecord(ChatId, audioFormat, "RU-ru", clientStartOffset);
        _ = _sourceAudioRecorder.RecordSourceAudio(_session, audioRecord, AudioChannel.Reader, default);
    }

    [JSInvokable]
    public void OnAudioData(byte[] chunk)
    {
        if (AudioChannel == null)
            return;
        _ = AudioChannel.Writer.WriteAsync(new BlobPart(Index++, chunk));
    }

    [JSInvokable]
    public void OnStopRecording()
    {
        // Does the same as StopRecording; we assume here that recording
        // might be recognized as stopped by JS backend as well
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
    }
}

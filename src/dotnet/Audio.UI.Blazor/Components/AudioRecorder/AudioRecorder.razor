@using System.Threading.Channels
@namespace ActualChat.Audio.UI.Blazor
@implements IAudioRecorderBackend
@implements IAsyncDisposable
@inject Session _session
@inject IJSRuntime _js
@inject ISourceAudioRecorder _sourceAudioRecorder

<button @onclick ="ToggleRecording" class="block px-3 py-2 @(IsRecording ? "text-red-500" : "text-indigo-500")">
    <svg class="items-center fill-current" xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 28 28">
        <path d="M16 11c0 2.209-1.791 4-4 4s-4-1.791-4-4v-7c0-2.209 1.791-4 4-4s4 1.791 4 4v7zm4-2v2c0 4.418-3.582 8-8 8s-8-3.582-8-8v-2h2v2c0 3.309 2.691 6 6 6s6-2.691 6-6v-2h2zm-7 13v-2h-2v2h-4v2h10v-2h-4z" />
    </svg>
</button>


@code {
    private IJSObjectReference? JSComponentRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend> ComponentRef { get; set; } = null!;
    private Channel<BlobPart>? AudioChannel { get; set; }
    private int Index { get; set; }

    private bool IsRecording => AudioChannel != null;
    //private Color ToggleColor => IsRecording ? Color.Secondary : Color.Primary;

    [Parameter]
    public string ChatId { get; set; } = "";

    public async ValueTask DisposeAsync()
    {
        await StopRecording().ConfigureAwait(true);
        ComponentRef?.Dispose();
        if (JSComponentRef != null)
            await JSComponentRef.DisposeSilentAsync().ConfigureAwait(true);
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender) {
            ComponentRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
            JSComponentRef = await _js.InvokeAsync<IJSObjectReference>($"{AudioBlazorUIModule.ImportName}.AudioRecorder.create", ComponentRef);
        }
    }

    private Task ToggleRecording()
        => IsRecording ? StopRecording() : StartRecording();

    private async Task StartRecording()
    {
        if (AudioChannel != null)
            return;

        AudioChannel = Channel.CreateBounded<BlobPart>(
            new BoundedChannelOptions(100) {
                FullMode = BoundedChannelFullMode.Wait,
                SingleWriter = true,
                AllowSynchronousContinuations = true,
            });
        StateHasChanged();
        if (JSComponentRef != null)
            await JSComponentRef.InvokeVoidAsync("startRecording");
    }

    private async Task StopRecording()
    {
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
        if (JSComponentRef != null)
          await JSComponentRef.InvokeVoidAsync("stopRecording");
    }

    // JS backend callback handlers

    [JSInvokable]
    public void OnStartRecording()
    {
        if (AudioChannel == null)
            return;

        var audioFormat = new AudioFormat {
            CodecKind = AudioCodecKind.Opus,
            ChannelCount = 1,
            SampleRate = 48_000
        };
        var clientStartOffset = CpuClock.Now.EpochOffset.TotalSeconds;
        var audioRecord = new AudioRecord(ChatId, audioFormat, "RU-ru", clientStartOffset);
        _ = _sourceAudioRecorder.RecordSourceAudio(_session, audioRecord, AudioChannel.Reader, default);
    }

    [JSInvokable]
    public void OnAudioData(byte[] chunk)
    {
        if (AudioChannel == null)
            return;
        _ = AudioChannel.Writer.WriteAsync(new BlobPart(Index++, chunk));
    }

    [JSInvokable]
    public void OnStopRecording()
    {
        // Does the same as StopRecording; we assume here that recording
        // might be recognized as stopped by JS backend as well
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
    }
}

@namespace ActualChat.Audio.UI.Blazor.Components
@implements IAudioRecorderBackend
@using ActualChat.Audio.UI.Blazor.Module
@using ActualChat.Media
@using System.Buffers.Binary
@implements IAsyncDisposable
@inject Session _session
@inject IJSRuntime _js
@inject ISourceAudioRecorder _sourceAudioRecorder

@{
    var cls = "";
    if (IsRecording)
        cls += "recording";
    else {
        cls += "not-recording";
    }
}

<button @onclick="ToggleRecording" class="@(_class ??= this.DefaultClass()) outline-none py-2 pr-3 rounded-r-full bg-transparent max-h-12 transition-all duration-150">
    <svg class="items-center fill-current @cls" xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="-2 -2 28 28">
        <path d="M16 11c0 2.209-1.791 4-4 4s-4-1.791-4-4v-7c0-2.209 1.791-4 4-4s4 1.791 4 4v7zm4-2v2c0 4.418-3.582 8-8 8s-8-3.582-8-8v-2h2v2c0 3.309 2.691 6 6 6s6-2.691 6-6v-2h2zm-7 13v-2h-2v2h-4v2h10v-2h-4z"/>
    </svg>
</button>

@code {
    private static string? _class;

    [Inject] private ILogger<AudioRecorder> Log { get; init; } = null!;
    private ILogger? DebugLog => DebugMode ? Log : null;
    private bool DebugMode => Constants.DebugMode.AudioRecording;

    private IJSObjectReference? JSRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend> BlazorRef { get; set; } = null!;
    private Channel<RecordingPart>? AudioChannel { get; set; }
    private int Index { get; set; }
    private bool IsRecording => AudioChannel != null;

    [Parameter]
    public string ChatId { get; set; } = "";

    public async ValueTask DisposeAsync() {
        await StopRecording().ConfigureAwait(true);
        await JSRef.DisposeSilentlyAsync().ConfigureAwait(true);
        // ReSharper disable once ConstantConditionalAccessQualifier
        BlazorRef?.Dispose();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender) {
        if (firstRender) {
            BlazorRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
            JSRef = await _js.InvokeAsync<IJSObjectReference>(
                $"{AudioBlazorUIModule.ImportName}.AudioRecorder.create",
                BlazorRef, DebugMode
                ).ConfigureAwait(true);
        }
        DebugLog?.LogDebug(
            "OnAfterRender: Chat #{ChatId}, firstRender = {FirstRender}",
            ChatId, firstRender);
    }

    private Task ToggleRecording()
        => IsRecording ? StopRecording() : StartRecording();

    private async Task StartRecording() {
        if (AudioChannel != null)
            return;

        AudioChannel = Channel.CreateBounded<RecordingPart>(
            new BoundedChannelOptions(128) {
                SingleWriter = true,
                SingleReader = true,
                AllowSynchronousContinuations = true,
            });
        StateHasChanged();
        if (JSRef != null)
            await JSRef.InvokeVoidAsync("startRecording");
        DebugLog?.LogDebug("StartRecording");
    }

    private async Task StopRecording() {
        DebugLog?.LogDebug("StopRecording, current AudioChannel status is {AudioChannelStatus}",
            AudioChannel == null ? "closed" : "opened"
        );

        if (AudioChannel == null)
            return;
        try {
            if (JSRef != null)
                await JSRef.InvokeVoidAsync("stopRecording");
        }
        finally {
            if (AudioChannel != null) {
                AudioChannel.Writer.Complete();
                AudioChannel = null;
                StateHasChanged();
            }
        }
    }

    // JS backend callback handlers

    [JSInvokable]
    public void OnStartRecording() {
        if (AudioChannel == null)
            return;

        var audioFormat = new AudioFormat {
            CodecKind = AudioCodecKind.Opus,
            ChannelCount = 1,
            SampleRate = 48_000,
        };
        var clientStartOffset = CpuClock.Now.EpochOffset.TotalSeconds;
        var audioRecord = new AudioRecord(ChatId, audioFormat, "RU-ru", clientStartOffset);
        var audioStream = AudioChannel.Reader.ReadAllAsync(CancellationToken.None);
        _ = BackgroundTask.Run(
            () => _sourceAudioRecorder.RecordSourceAudio(_session, audioRecord, audioStream, CancellationToken.None),
            Log, $"{nameof(_sourceAudioRecorder.RecordSourceAudio)} failed");
    }

    [JSInvokable]
    public async Task OnAudioEventChunk(byte[] chunk) {
        if (AudioChannel == null)
            return;

        foreach (var part in ParseEventChunk(chunk)) {
            await AudioChannel.Writer.WriteAsync(part);
        }
        DebugLog?.LogDebug("OnAudioEventChunk: got packet {Chunk}", chunk);
    }

    [JSInvokable]
    public void OnRecordingStopped() {
        DebugLog?.LogDebug("OnRecordingStopped: current AudioChannel status is {AudioChannelStatus}",
            AudioChannel == null ? "closed" : "opened"
        );
        // Does the same as StopRecording; we assume here that recording
        // might be recognized as stopped by JS backend as well
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
    }

    private IEnumerable<RecordingPart> ParseEventChunk(byte[] chunk) {
        var offset = 0;
        while (offset < chunk.Length) {
            var type = (RecordingEventType)chunk[offset++];
            var length = BinaryPrimitives.ReadUInt16LittleEndian(chunk[offset..]);
            offset += 2;
            var startData = offset;
            offset += length;
            yield return type switch
            {
                RecordingEventType.Data => new() {
                    Data = chunk[startData..(startData + length)].ToArray(),
                },
                RecordingEventType.Pause => new() {
                    Command = RecordingCommand.Pause,
                },
                RecordingEventType.Resume => new() {
                    Command = RecordingCommand.Resume,
                },
                RecordingEventType.Voice => new() {
                    VoiceProbability = BinaryPrimitives.ReadSingleLittleEndian(chunk[startData..]),
                },
                RecordingEventType.Timestamp => new() {
                    UtcTicks = BinaryPrimitives.ReadInt64LittleEndian(chunk[startData..]),
                },
                _ => throw new ArgumentOutOfRangeException(),
            };
        }
    }
}


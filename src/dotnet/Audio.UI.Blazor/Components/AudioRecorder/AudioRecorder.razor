@namespace ActualChat.Audio.UI.Blazor.Components
@implements IAudioRecorderBackend
@implements IAsyncDisposable
@inject Session _session
@inject IJSRuntime _js
@inject ISourceAudioRecorder _sourceAudioRecorder

<button @onclick="ToggleRecording" class="block px-3 py-2 @(IsRecording ? "text-red-500" : "text-indigo-500")">
    <svg class="items-center fill-current" xmlns="http://www.w3.org/2000/svg" width="28" height="28" viewBox="0 0 28 28">
        <path d="M16 11c0 2.209-1.791 4-4 4s-4-1.791-4-4v-7c0-2.209 1.791-4 4-4s4 1.791 4 4v7zm4-2v2c0 4.418-3.582 8-8 8s-8-3.582-8-8v-2h2v2c0 3.309 2.691 6 6 6s6-2.691 6-6v-2h2zm-7 13v-2h-2v2h-4v2h10v-2h-4z" />
    </svg>
</button>

@code {
    private static byte[] _brokenHeader1 = { 0x45, 0xDF, 0xA3, 0x9F, 0x42, 0x86 };
    private static byte[] _brokenHeader2 = { 0x1A, 0x1A, 0x45, 0xDF, 0xA3, 0x9F };

    [Inject]
    protected ILogger<AudioRecorder> Log { get; init; } = null!;
    protected ILogger? DebugLog => DebugMode ? Log : null;
    private bool DebugMode { get; } = Constants.DebugMode.AudioRecording;

    private IJSObjectReference? JSComponentRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend> ComponentRef { get; set; } = null!;
    private Channel<BlobPart>? AudioChannel { get; set; }
    private int Index { get; set; }

    private bool IsRecording => AudioChannel != null;
    //private Color ToggleColor => IsRecording ? Color.Secondary : Color.Primary;


    [Parameter]
    public string ChatId { get; set; } = "";

    public async ValueTask DisposeAsync()
    {
        await StopRecording().ConfigureAwait(true);
        await JSComponentRef.DisposeSilentlyAsync().ConfigureAwait(true);
        ComponentRef?.Dispose();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender) {
            ComponentRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
            JSComponentRef = await _js.InvokeAsync<IJSObjectReference>($"{AudioBlazorUIModule.ImportName}.AudioRecorder.create", ComponentRef, DebugMode);
        }
        DebugLog?.LogInformation("OnAfterRender: ChatId = {ChatId}, AudioRecorder loaded", ChatId);
    }

    private Task ToggleRecording()
        => IsRecording ? StopRecording() : StartRecording();

    private async Task StartRecording()
    {
        if (AudioChannel != null)
            return;

        AudioChannel = Channel.CreateBounded<BlobPart>(
            new BoundedChannelOptions(128) {
                SingleWriter = true,
                SingleReader = true,
                AllowSynchronousContinuations = true,
            });
        StateHasChanged();
        if (JSComponentRef != null)
            await JSComponentRef.InvokeVoidAsync("startRecording");
        DebugLog?.LogInformation("StartRecording: Invoked");
    }

    private async Task StopRecording()
    {
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
        if (JSComponentRef != null)
          await JSComponentRef.InvokeVoidAsync("stopRecording");
        DebugLog?.LogInformation("StopRecording: Invoked");
    }

    // JS backend callback handlers

    [JSInvokable]
    public void OnStartRecording()
    {
        if (AudioChannel == null)
            return;

        var audioFormat = new AudioFormat {
            CodecKind = AudioCodecKind.Opus,
            ChannelCount = 1,
            SampleRate = 48_000,
        };
        var clientStartOffset = CpuClock.Now.EpochOffset.TotalSeconds;
        var audioRecord = new AudioRecord(ChatId, audioFormat, "RU-ru", clientStartOffset);
        var audioStream = AudioChannel.Reader.ReadAllAsync(CancellationToken.None);
        _ = BackgroundTask.Run(
            () => _sourceAudioRecorder.RecordSourceAudio(_session, audioRecord, audioStream, CancellationToken.None),
            Log, $"{nameof(_sourceAudioRecorder.RecordSourceAudio)} failed");
    }

    [JSInvokable]
    public async Task OnAudioData(byte[] chunk)
    {
        if (AudioChannel == null)
            return;

        var seqNum = Unsafe.As<byte, uint>(ref chunk[0]);
        chunk = chunk[4..];
        DebugLog?.LogInformation("Got the packet (seqNum: {SequenceNumber}, data bytes: {PacketDataBytes})", seqNum, chunk.Length);
        await AudioChannel.Writer.WriteAsync(new BlobPart(Index++, chunk));
    }

    [JSInvokable]
    public void OnStopRecording()
    {
        // Does the same as StopRecording; we assume here that recording
        // might be recognized as stopped by JS backend as well
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
    }
}

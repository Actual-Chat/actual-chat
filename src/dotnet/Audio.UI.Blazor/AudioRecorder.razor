@using System.Threading.Channels
@using ActualChat.Streaming
@implements IAudioRecorderBackend
@implements IAsyncDisposable
@inject Session _session
@inject IJSRuntime _js
@inject JSModule _jsModule;
@inject IAudioRecorder _audioRecorder

<Button Type="@ButtonType.Button" Clicked="ToggleRecording" Color="@ToggleColor">
    <Blazorise.Icon Name="@FontAwesomeIcons.Microphone"/>
</Button>

@code {
    private IJSObjectReference ModuleRef { get; set; } = null!;
    protected IJSObjectReference? JSComponentRef { get; set; }
    private DotNetObjectReference<IAudioRecorderBackend> ComponentRef { get; set; } = null!;
    private Channel<BlobPart>? AudioChannel { get; set; }
    private int Index { get; set; }

    private bool IsRecording => AudioChannel != null;
    private Color ToggleColor => IsRecording ? Color.Secondary : Color.Primary;

    [Parameter]
    public string ChatId { get; set; } = "";

    public async ValueTask DisposeAsync()
    {
        await StopRecording();
        ComponentRef?.Dispose();
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
      if (firstRender) {
        ModuleRef = await _jsModule.Import(typeof(AudioPage).Assembly, "js/audio-recorder.js");
        ComponentRef = DotNetObjectReference.Create<IAudioRecorderBackend>(this);
        JSComponentRef = await ModuleRef.InvokeAsync<IJSObjectReference>("create", ComponentRef);
      }
    }

    private Task ToggleRecording()
        => IsRecording ? StopRecording() : StartRecording();

    private async Task StartRecording()
    {
        if (AudioChannel != null)
            return;

        AudioChannel = Channel.CreateBounded<BlobPart>(
            new BoundedChannelOptions(100) {
                FullMode = BoundedChannelFullMode.Wait,
                SingleReader = true,
                SingleWriter = true,
                AllowSynchronousContinuations = true
            });
        StateHasChanged();
        if (JSComponentRef != null)
            await JSComponentRef.InvokeVoidAsync("startRecording");
    }

    private async Task StopRecording()
    {
        if (AudioChannel == null)
            return;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        if (JSComponentRef != null)
          await JSComponentRef.InvokeVoidAsync("stopRecording");

        StateHasChanged();

    }

    // JS backend callback handlers

    [JSInvokable]
    public Task OnStartRecording()
    {
        if (AudioChannel == null)
            return Task.CompletedTask;

        var record = new AudioRecord(
            ChatId,
            new AudioFormat { Codec = AudioCodec.Opus, ChannelCount = 1, SampleRate = 48_000 },
            "RU-ru",
            CpuClock.Now.EpochOffset.TotalSeconds);
        _ = _audioRecorder.Record(_session, record, AudioChannel.Reader, default);
        return Task.CompletedTask;
    }

    [JSInvokable]
    public async Task OnAudioData(byte[] chunk)
    {
        if (AudioChannel == null)
            return;
        await AudioChannel.Writer.WriteAsync(new BlobPart(Index++, chunk));
    }

    [JSInvokable]
    public Task OnStopRecording()
    {
        // Does the same as StopRecording; we assume here that recording
        // might be recognized as stopped by JS backend as well
        if (AudioChannel == null)
            return Task.CompletedTask;

        AudioChannel.Writer.Complete();
        AudioChannel = null;
        StateHasChanged();
        return Task.CompletedTask;
    }

}
